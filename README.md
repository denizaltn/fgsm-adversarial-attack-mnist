# FGSM ile Yapay ZekayÄ± KandÄ±rmak: Adversarial SaldÄ±rÄ± UygulamasÄ±

Bu proje, yapay zeka sistemlerinin zayÄ±f noktalarÄ±nÄ± keÅŸfetmek ve savunma stratejileri geliÅŸtirmek amacÄ±yla geliÅŸtirilmiÅŸtir. Derin Ã¶ÄŸrenme modellerinin ne kadar gÃ¼Ã§lÃ¼ gÃ¶rÃ¼nse de kÃ¼Ã§Ã¼k manipÃ¼lasyonlarla nasÄ±l yanÄ±ltÄ±labileceÄŸini gÃ¶stermek temel hedeftir.

## Proje HakkÄ±nda

Bu Ã§alÄ±ÅŸmada, **MNIST** veri seti kullanÄ±larak bir **CNN (Convolutional Neural Network)** modeli eÄŸitilmiÅŸ ve ardÄ±ndan bu modele **FGSM (Fast Gradient Sign Method)** adlÄ± adversarial saldÄ±rÄ± uygulanmÄ±ÅŸtÄ±r.

### Uygulanan AdÄ±mlar:

1. **Model EÄŸitimi:**  
   - MNIST veri seti Ã¼zerinde bir CNN modeli eÄŸitildi.  
   - Model, yÃ¼ksek doÄŸruluk oranÄ± (%97+) elde edecek ÅŸekilde optimize edildi.

2. **FGSM SaldÄ±rÄ±sÄ±:**  
   - EÄŸitilen model Ã¼zerinde FGSM yÃ¶ntemiyle adversarial Ã¶rnekler (bozulmuÅŸ gÃ¶rÃ¼ntÃ¼ler) oluÅŸturuldu.  
   - Modelin bu Ã¶rneklerde nasÄ±l hata yaptÄ±ÄŸÄ± gÃ¶zlemlendi.  
   - Orijinal ve bozulmuÅŸ gÃ¶rÃ¼ntÃ¼ler karÅŸÄ±laÅŸtÄ±rmalÄ± olarak analiz edildi.

3. **Adversarial Training (Ä°steÄŸe BaÄŸlÄ±):**  
   - Model, hem orijinal hem de bozulmuÅŸ verilerle yeniden eÄŸitilerek saldÄ±rÄ±lara karÅŸÄ± daha dayanÄ±klÄ± hale getirildi.

## Daha FazlasÄ± Ä°Ã§in


ğŸ”— **Makale:**  
ğŸ‘‰ [https://medium.com/@deniz0](https://medium.com/@deniz0)






---
